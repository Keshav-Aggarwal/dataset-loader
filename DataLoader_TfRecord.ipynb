{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import progressbar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logger.add(sys.stderr, format=\"{time} {level} {message}\", filter=\"my_module\", level=\"INFO\")\n",
    "logger.add(sys.stdout, colorize=True, format=\"<green>{time}</green> <level>{message}</level>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTIL FUNCTIONS\n",
    "class utils:\n",
    "    def __init__(self, logs):\n",
    "        self.logs = logs\n",
    "\n",
    "    def splitpath(self,p):\n",
    "        return p.split('/')[1]\n",
    "\n",
    "    def read_img(self,path, size = None):\n",
    "        if size is None:\n",
    "                return plt.imread(path)\n",
    "        return cv2.resize(plt.imread(path), size)\n",
    "\n",
    "    def shuffle_labeled_data(self,imgs, lbls):\n",
    "        combined = list(zip(imgs, lbls))\n",
    "        shuffle(combined)\n",
    "        imgs[:], lbls[:] = zip(*combined)\n",
    "        return imgs, lbls\n",
    "\n",
    "    def export_pickle(self, imgs, lbls, export_pickle_name):\n",
    "        with open(export_pickle_name, 'wb') as handle:\n",
    "            pickle.dump(zip(imgs, lbls), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            self.log_messages(\"Data is saved in pickle file with name {}\".format(export_pickle_name), self.logs)\n",
    "\n",
    "    def import_pickle(self, import_pickle_name):\n",
    "        print(import_pickle_name)\n",
    "        imgs = []\n",
    "        lbls = []\n",
    "        with open(import_pickle_name, 'rb') as handle:\n",
    "            imgs[:], lbls[:] = zip(*pickle.load(handle))\n",
    "            self.log_messages(\"Total {} images and labels loaded from pickle file.\".format(len(imgs)), self.logs)\n",
    "            return imgs, lbls\n",
    "\n",
    "    def log_messages(self, msg, log=False):\n",
    "        if(log):\n",
    "            logger.log(10, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIL = utils(True)\n",
    "def get_img_data_gen(classes_path, classes, get_path_only, shuffle_data, img_format=\"png\", \n",
    "                 resize = None, batch_size = 32):\n",
    "    imgs = []\n",
    "    lbls = []\n",
    "\n",
    "    for cp, c in zip(classes_path, classes):\n",
    "        imgs_path = glob.glob(\"{}/*.{}\".format(cp,img_format))\n",
    "        imgs.extend(imgs_path)\n",
    "        lbls.extend([c] * len(imgs_path))\n",
    "    \n",
    "    if(shuffle_data):\n",
    "        imgs, lbls = UTIL.shuffle_labeled_data(imgs, lbls)\n",
    "\n",
    "    total_batches = len(imgs) / batch_size\n",
    "    for i in range(int(total_batches)):\n",
    "        imgs_y = (UTIL.read_img(x, resize) for x in imgs[batch_size*i : batch_size*(i+1)])\n",
    "        lbls_y = lbls[batch_size*i : batch_size*(i+1)]\n",
    "        \n",
    "    yield zip(imgs_y, lbls_y)\n",
    "\n",
    "def progressBar(i, x, resize, bar):\n",
    "    bar.update(i)\n",
    "    return UTIL.read_img(x, resize)\n",
    "\n",
    "def get_img_data(classes_path, classes, get_path_only, shuffle_data, img_format=\"png\", \n",
    "                 resize = None, batch_size = 32, return_generator = False):\n",
    "    imgs = []\n",
    "    lbls = []\n",
    "\n",
    "    for cp, c in zip(classes_path, classes):\n",
    "        imgs_path = glob.glob(\"{}/*.{}\".format(cp,img_format))\n",
    "        imgs.extend(imgs_path)\n",
    "        lbls.extend([c] * len(imgs_path))\n",
    "    \n",
    "    if(shuffle_data):\n",
    "        imgs, lbls = UTIL.shuffle_labeled_data(imgs, lbls)\n",
    "    \n",
    "    if get_path_only:\n",
    "        return imgs, lbls\n",
    "    progress = progressbar.ProgressBar()\n",
    "            \n",
    "    imgs = [UTIL.read_img(x, resize) for x in progress(imgs)] #list(map(read_img, imgs))\n",
    "    \n",
    "#     with progressbar.ProgressBar(maxval=len(imgs)) as bar:\n",
    "#         imgs = [progressBar(i,x,resize, bar) for i, x in enumerate(imgs)] #list(map(read_img, imgs))\n",
    "    return imgs, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERATED SIZE OF TFRECORD IS LARGE BECAUSE WE USED INT64...\n",
    "\n",
    "def get_img_data_tfrecord(classes_path, labels, resize = (128,128), shuffle_data = True, img_format='.jpg'):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "    with tf.io.TFRecordWriter('tfrecord.tfrecord') as writer:\n",
    "        imgs = []\n",
    "        lbls = []\n",
    "        progress = progressbar.ProgressBar()\n",
    "        for cp, c in zip(classes_path, labels):\n",
    "            imgs_path = glob.glob(\"{}/*.{}\".format(cp,img_format))\n",
    "            imgs.extend(imgs_path)\n",
    "            lbls.extend([c] * len(imgs_path))\n",
    "        \n",
    "        for index in progress(range(len(imgs_path))):\n",
    "            image_raw = UTIL.read_img(imgs[index])\n",
    "            images = image_raw.tostring()\n",
    "            \n",
    "            rows = image_raw.shape[0]\n",
    "            cols = image_raw.shape[1]\n",
    "            depth = image_raw.shape[2]\n",
    "\n",
    "            example = tf.train.Example(\n",
    "              features=tf.train.Features(\n",
    "                  feature={\n",
    "                      'height': _int64_feature(rows),\n",
    "                      'width': _int64_feature(cols),\n",
    "                      'depth': _int64_feature(depth),\n",
    "                      'label': _int64_feature(int(lbls[index])),\n",
    "                      'image_raw': _bytes_feature(images)\n",
    "                  }))\n",
    "            writer.write(example.SerializeToString())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_load(dataset_dir, class_source, csv_path = None, get_path_only = False, img_format='jpg', \n",
    "                 resize = None, export_pickle_name = 'data.pickle', shuffle_data = True, log_msgs = True,\n",
    "                 batch_size = 32, return_generator = False, save_tfrecord = False):\n",
    "    classes = []\n",
    "    imgs = []\n",
    "    start_time = time.time()\n",
    "    if class_source == 'FOLDER':\n",
    "        classes_path = glob.glob(dataset_dir+'/*')\n",
    "        classes = list(map(UTIL.splitpath, classes_path))\n",
    "        \n",
    "        if(return_generator):\n",
    "            generator_x = get_img_data_gen(classes_path, classes, get_path_only, img_format=img_format, resize = resize, shuffle_data = shuffle_data, batch_size=batch_size)\n",
    "            UTIL.log_messages(\"Total time taken {}\".format(int(time.time() - start_time)))\n",
    "            return generator_x\n",
    "        \n",
    "        if(save_tfrecord):\n",
    "            tfrecord = get_img_data_tfrecord(classes_path, classes, get_path_only, img_format=img_format, shuffle_data = shuffle_data)\n",
    "            UTIL.log_messages(\"Saved tfrecord file\", True)\n",
    "            return 0,0\n",
    "        \n",
    "        imgs, lbls = get_img_data(classes_path, classes, get_path_only, img_format=img_format, resize = resize, shuffle_data = shuffle_data)\n",
    "        UTIL.log_messages(\"Total time taken {}\".format(int(time.time() - start_time)), True)\n",
    "        \n",
    "        if export_pickle_name is not None:\n",
    "            UTIL.export_pickle(imgs, lbls, export_pickle_name)\n",
    "        UTIL.log_messages(\"Total time taken {}\".format(int(time.time() - start_time)))\n",
    "        return imgs, lbls\n",
    "    \n",
    "    if class_source == 'CSV':\n",
    "        assert (csv_path is not None), \"Please provide a valid CSV file path\"\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        classes = list(df[\"class\"])\n",
    "        imgs_path = list(df[\"path\"])\n",
    "        if(shuffle_data):\n",
    "            imgs, lbls = UTIL.shuffle_labeled_data(imgs_path, classes)\n",
    "            \n",
    "        imgs = [UTIL.read_img(x, size=resize) for x in imgs_path] #map(read_img, list(df[\"path\"]))       \n",
    "        \n",
    "        UTIL.log_messages(\"Total images {}\".format(len(imgs)), log_msgs)    \n",
    "\n",
    "        if export_pickle_name is not None:\n",
    "            UTIL.export_pickle(imgs, lbls, export_pickle_name)\n",
    "        UTIL.log_messages(\"Total time taken {}\".format(time.time() - start_time))\n",
    "        return imgs, lbls\n",
    "    \n",
    "def dataset_load_pickle(path, shuffle = True):\n",
    "    imgs, lbls = UTIL.import_pickle(path)\n",
    "    if shuffle:\n",
    "        imgs, lbls = UTIL.shuffle_labeled_data(imgs, lbls)\n",
    "    return imgs,lbls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "imgs, lbls = dataset_load('dataset/', 'FOLDER',get_path_only = False, img_format='jpg', save_tfrecord=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_load_pickle('data.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
